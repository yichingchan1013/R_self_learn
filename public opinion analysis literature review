## Public Opinion Analysis 

### Topic
> * cyber army detection on social media 
> * from abnormal behavior to content analysis
> * key word: ???

### Course Info
如欲修課的同學，請於開學第一週前將三頁初步計畫書以E-mail寄送給開課教師（MUST）。
初步計畫書內容須包含，研究主題、研究前沿（網路上別人做到哪裡，請找英文）、所欲處理的資料、個人的程式學習狀況概述、個人修課的需求、本學期其他修課概況。

### Resource
[foundations of statistical natural language processing]()   
[MPA 635](https://datavizf18.classes.andrewheiss.com/)   
[Datand](https://jouryllabus)   


### week1_12/01

> **Stat**   
> * finished **Chapter16 Categorical Outcomes** of *Experimental Design & Analysis*   
> * Reviewed **Chapter16 Chi-square Test** of *Statistics*      

### Opinion Spam Detection in Web Forum: A Real Case Study 

> * Author: Yu-Ren Chen and Hsin-Hsi Chen
> * Keywords: Fake Web Review; Opinion Spam Detection; Web Forum. 
> * summary: 利用被揭露出的三星寫手門事件mobile01真實資料，區分付費寫手的發文與真實發文者的區別。
    作者以三個實體 - 貼文串(threads)、首文(posts)、個人檔案(profiles)為對象，
    產出眾多feature，如發文時間、發文日期、發文字數、發文圖片佔比、發文英文字佔比、發文提及品牌次數、首文是否為寫手文等，
    再結合發文的原始文本內容，對其進行斷詞後找出bag-of-word再以PCA降維，試圖以前述feature及文本內容建立預測文章是否為寫手發文的模型。
    本研究結論為寫手文目的是在炒熱討論，然而就主文與回文有如下的差異
    (a)主文而言會將重點放在使用者體驗，傾向會有較多圖與文字，發文時間為上班時間，討論也會較為熱烈，模型判定是否為寫手較容易
    (b)因回文以維繫熱度為前提，又因為回文的寫手文章比率較低，相對較難以判斷
> * techniques: Web Crawling, Descriptive Statistics, Bag-of-Words(結巴斷詞), Sentiment Analysis(情感分析), PCA(主成分分析), text classification(文本分類)
    利用 Scikit-Learn, Logistic Regression, SVM with linear kernel, SVM with RBF kernel 等演算法

### Analysis of Cyber Army’s Behaviours on Web Forum for Elect Campaign

> * Author: Man-Chun Ko and Hsin-Hsi Chen
> * Keywords: Cyber army; Deception; Opinion spammer
> * summary: 利用被揭露出的2014連柯台北市長選舉ptt網軍帳號資料，研究網軍發文的行為。
    作者以三個實體 - 推噓文(comments)、發文(articles)、個人檔案(users)為對象，
    比較已知網軍組與對照組(treatment group)的行為差別，抓出兩組人於特定時間段的發文紀錄並進行比較。
    本研究發現主要差別在於
    (a)發文數量: 網軍組較對照組多出許多
    (b)發文時間: 網軍組多半在上班時間發文
    (c)發文內容: 就發文紀錄而言，兩組的市長選舉相關發文比例相似，但網軍組(連陣營)的發文與推噓文以攻擊對方陣營較多
> * techniques: Web Crawling, Descriptive Statistics

### Boosting Election Prediction Accuracy by Crowd Wisdom on Social Forums

> * Author: Ming-Hung Wang and Chin-Laung Lei
> * Keywords: Cyber army; Deception; Opinion spammer
> * summary: 利用社群網站ptt上的選舉相關文章，以情感分析與peer to peer ratings預測選舉結果與得票率。
    除了傳統民調以外，以社群媒體內容進行選舉預測者主要採取兩個做法: 聲量大小為基礎(volume-based)與情感為基礎(sentiment-based)，
    但上述方法主要以發文者的發文內容(text body of uauthor-generated content)為關注重點，忽略了非發文者的留言者，
    此外即使作者發了很多篇文，以發文者為關注重點的方法卻只會計算一次(they can only vote once in the election)，造成誤差，
    本篇即是作者修改前人做法後的調整，主要強調兩點，第一是利用peer-to-peer ratings計算候選人被接受度用來平衡關注發文者與留言者，
    第二是結合三種指標得出總體分數以建構模型，分別是peer-to-peer ratings, sentiment scores, and candidate mentioning volumes。
    主要貢獻有三(1)(2)利用時段分析(temporal analysis)(3)
    就**研究方法**而言，本研究的順序如下
    (1)中文斷詞: 因社群媒體上用字與正式場合用字不同，考慮斷詞效果，本研究首先以結巴對每篇文章斷詞，剔除停止詞後計算文字使用頻率，
    選取使用頻率最高的2000個字之後手動確認斷詞後的語意是否是否合宜，而後將篩選過後的使用頻率最高的1000個字加入字典，再一次進行斷詞。
    (2)聲量計算: 對每篇文的每個詞進行確認，若文章有詞包含候選人相關名稱，則判定屬於該候選人相關文章，同篇文可能同時和多位候選人有關。
    (3)情緒分數計算: 對每篇文的每個詞進行確認，依據詞彙的正負替候選人的正負情緒分數各自加分。
    (4)候選人被接受度: 前面的聲量與情緒分數計算對象皆為發文(articles)，本指標的計算對象則涵蓋推噓文(comments)，
    計算每篇候選人相關發文累積的推噓後各自加總，兩者相減後得到候選人被接受度分數。
    (5)Smoothing: 為捕捉時序效果，本研究以日為單位計算上述三項指標，但因為選舉的特性包含不特定的重大事件，需要進行撫平(smoothing)，
    又考慮到離選舉近的事件影響更大，故另外進行了N-day exponential weighted moving average (EWMA) on daily observations.
    實際計算方法請參考論文。
    (6)Hybrid Election Forecasting: VS = (Volume + Sentiment + Public.Acceptance)^2, VS代表vote share
    就**實際案例**而言，本研究以台灣2014六都市長選舉為主題，爬了PTT上八卦版與政黑版選前三個月的文章與推噓，進行了時間序列分析與選舉預測:
    (1)Time-series analysis: 以Z分數正規化前述的三項指標後，執行時間序列分析預測選舉結果
    (2)Prediction model accuracy: 以線性迴歸模型預測選舉結果，再和學界傳統兩種方法比較預測結果
    作者以三個實體 - 推噓文(comments)、發文(articles)、個人檔案(users)為對象，
    比較已知網軍組與對照組(treatment group)的行為差別，抓出兩組人於特定時間段的發文紀錄並進行比較。
    本研究發現主要差別在於
    (a)發文數量: 網軍組較對照組多出許多
    (b)發文時間: 網軍組多半在上班時間發文
    (c)發文內容: 就發文紀錄而言，兩組的市長選舉相關發文比例相似，但網軍組(連陣營)的發文與推噓文以攻擊對方陣營較多
> * techniques: Web Crawling, Descriptive Statistics, Chinese Segmentation(結巴斷詞), Sentiment Analysis(情感分析), PCA(主成分分析), text classification(文本分類)
    利用 Scikit-Learn, Logistic Regression, SVM with linear kernel, SVM with RBF kernel 等演算法

### week7_01/13
> * used [*RSelenium*](https://tidyeval.tidyverse.org/index.html) to crawled comments on Google Play
> * practiced logistic regression to predict response rate, taking [how to make a churn model in R](https://lukesingham.com/how-to-make-a-churn-model-in-r/) as the reference
> * read several studies related to applications of text mining in political science and social media analysis
> * completed my final essay titled **nature of playing sports-themed video games**, assigned by philosophical approaches to games' professor
> **Reading**: 失控的謊言

### week8_01/20
> * Learned [**tidystringdist**](https://colinfay.me/tidystringdist/reference/tidy_stringdist.html) packge
> * Digged deeper into [**purrr**](https://colinfay.me/tidystringdist/reference/tidy_stringdist.html) packge, recommended [**使用purrr package學functional programming的觀念**](https://weitinglin.com/tag/purrr/), a series of articles teaching purrr
> * prepared for Dr.Hsieh's Public Opinion Analysis class' research proposal, focusing on cyber/water army detection, read 3 research papers related to the topic
> * finished 50 pages of [*foundations of statistical natural language processing*](http://www.cookbook-r.com/Graphs/)
> * studied half of **SQL Fundamentals for Business Intelligence** on O'reilly Safiri, installed PSQL und used it for practice
> * Read at least 5 articles on [R-bloggers](https://www.cjr.org/index.php) daily
> **Reading**: 不當行為, 活著告訴你

### week9_01/27
> * 3.7 Save your work finished **Chapter2** of *Data Visualization*  
> * prepared for Dr.Hsieh's Public Opinion Analysis class' research proposal, focusing on cyber/water army detection
> * p.50 finished of [*foundations of statistical natural language processing*](http://www.cookbook-r.com/Graphs/)
> * studied half of **SQL Fundamentals for Business Intelligence** on O'reilly Safiri, installed PSQL und used it for practice
> * Read at least 5 articles on [R-bloggers](https://www.cjr.org/index.php) daily
> **Reading**: 不當行為, 活著告訴你

有機會讀Speech and Language Processing
性別力, 優秀的綿羊, 

### week10
> * finished **Chapter1** & **Chapter2** & **Chapter3** of [*R Graphics Cookbook*](http://www.cookbook-r.com/Graphs/)

### self-introduction
> * Name: Dennis Tseng
> * Major: Business Administration
> * School: National Taiwan University
> * Goal: keeping R self-learing notes

> "Practice makes perfect."

### R-related experience
> * self-studied 16+ courses on [Datacamp](https://www.datacamp.com)
> * finished first 7 chapters of [The art of R programming](http://diytranscriptomics.com/Reading/files/The%20Art%20of%20R%20Programming.pdf)
> * finished [Hands-On Programming with R](http://shop.oreilly.com/product/0636920028574.do)
> * finished [R for Data Science](http://r4ds.had.co.nz)
> * finished [Text Mining with R](https://www.tidytextmining.com/)
> * finished first 5 chapters of [Machine Learning with R](https://the-eye.eu/public/Books/Programming/Machine%20Learning%20with%20R%20-%20Second%20Edition%20%5BeBook%5D.pdf)

### Homework & Project links
> * **Homework**: [`HW2`](https://dennishi0925.github.io/CSX_RProject_Spring_2018/week2/HW2.html), [`HW3`](https://dennishi0925.github.io/CSX_RProject_Spring_2018/week3/HW3.html)
> * **Project**: [`project1`](
https://dennishi0925.github.io/CSX_RProject_Spring_2018/project1/project01.html), [`project2`](https://docs.google.com/presentation/d/1VWUVwEL3ItNMLSffdv3-53xGA-xP0vYW7hlBx3MF0u8/edit#slide=id.p)

